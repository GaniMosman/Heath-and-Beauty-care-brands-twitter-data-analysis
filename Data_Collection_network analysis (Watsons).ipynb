{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "from collections import Counter\n",
    "import time\n",
    "import math\n",
    "import matplotlib.pyplot as plt \n",
    "from tweepy import Cursor\n",
    "import tweepy\n",
    "from tweepy import OAuthHandler\n",
    "import datetime\n",
    "import csv\n",
    "import networkx as nx\n",
    "from operator import itemgetter\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "\n",
    "\n",
    "#Variables that contains the user credentials to access Twitter API\n",
    "access_token = \"\"\n",
    "access_token_secret = \"\"\n",
    "consumer_key = \"\"\n",
    "consumer_secret = \"\"\n",
    "\n",
    "# authentication\n",
    "auth = OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "api = tweepy.API(auth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory created\n"
     ]
    }
   ],
   "source": [
    "screen_name = 'watsonsmy'\n",
    "#creating directory for to save the extracted data\n",
    "dirname = \"output_watsons/{}\".format(screen_name)\n",
    "try:\n",
    "    os.makedirs(dirname, mode=0o755, exist_ok=True)\n",
    "    print(\"Directory created\")\n",
    "except OSError:\n",
    "    print(\"Directory {} already exists\".format(dirname))\n",
    "except Exception as e:\n",
    "    print(\"Error while creating directory {}\".format(dirname))\n",
    "    print(e)\n",
    "    sys.exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting user's profile data\n",
      "User's profile data collected\n"
     ]
    }
   ],
   "source": [
    "# get user's profile(watsonsmy)\n",
    "screen_name = 'watsonsmy'\n",
    "print(\"Collecting user's profile data\")\n",
    "fname = \"output_watsons/{}/user_profile.json\".format(screen_name)\n",
    "#Saving the data into json file\n",
    "with open(fname, 'w') as f:\n",
    "    profile = api.get_user(screen_name=screen_name)        \n",
    "    f.write(json.dumps(profile._json, indent=4))\n",
    "\n",
    "print(\"User's profile data collected\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "task completed\n"
     ]
    }
   ],
   "source": [
    "#collecting friends information for watsons\n",
    "def paginate(items, n):\n",
    "    \"\"\"Generate n-sized chunks from items\"\"\"\n",
    "    for i in range(0, len(items), n):\n",
    "        yield items[i:i+n]\n",
    "        \n",
    "MAX_FRIENDS = 15000\n",
    "max_pages = math.ceil(MAX_FRIENDS / 5000)\n",
    "#collecting friends information.\n",
    "fname = \"output_watsons/{}/friends.json\".format(screen_name)\n",
    "with open(fname, 'w') as f:\n",
    "    for friends in Cursor(api.friends_ids, screen_name=screen_name).pages(max_pages):\n",
    "        for chunk in paginate(friends, 100):\n",
    "            users = api.lookup_users(user_ids=chunk)\n",
    "            for user in users:                   \n",
    "                f.write(json.dumps(user._json)+\"\\n\")\n",
    "        if len(friends) == 5000:\n",
    "            print(\"More results available. Sleeping for 60 seconds to avoid rate limit\")\n",
    "            time.sleep(60)\n",
    "print(\"task completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ohmostwanted\n",
      "kiranjassal11\n",
      "SkincareViralMY\n",
      "VancityReynolds\n",
      "MarkRuffalo\n",
      "chrishemsworth\n",
      "Renner4Real\n",
      "prattprattpratt\n",
      "RobertDowneyJr\n",
      "ChrisEvans\n",
      "twt_kecantikann\n",
      "AshaLiyana21\n",
      "AmandaImani91\n",
      "brandonleong_\n",
      "sashasaidin\n",
      "jiayitan1993\n",
      "tantannewsMY\n",
      "zeriz4\n",
      "imSarahLian\n",
      "revlon\n",
      "Colgate\n",
      "PFCosmetics\n",
      "OralB\n",
      "missfazura\n",
      "OlaySkin\n",
      "Nor4Danish\n",
      "Neutrogena\n",
      "linoralow\n",
      "HimalayaMAS\n",
      "ClinelleMy\n",
      "rimmellondonuk\n",
      "bourjois_uk\n",
      "bioreus\n",
      "AishaLiyana\n",
      "cetaphilMY\n",
      "GarnierMalaysia\n",
      "LOrealParisMY\n",
      "CLEARMalaysia\n",
      "SUNSILKMSIA\n",
      "WatsonsPH\n",
      "AaronDwiAziz\n",
      "Neelofa\n",
      "Shaheizy_Sam\n",
      "CTNurhaliza11\n",
      "yunamusic\n",
      "zizanrajalawak\n",
      "LisaSurihani\n",
      "MaybellineMY\n",
      "Zaidi_Aziz\n",
      "BELLAZAHIR\n",
      "ohbulancom\n",
      "SimplySitiSB\n",
      "kleioCo\n",
      "WatsonsSG\n",
      "amberchia\n"
     ]
    }
   ],
   "source": [
    "#creating list of friends for watsons to create nodes\n",
    "friends = []\n",
    "screen_name = 'watsonsmy'\n",
    "fname = \"output_watsons/{}/friends.json\".format(screen_name)\n",
    "\n",
    "with open(fname) as f:\n",
    "     for line in f:\n",
    "        profile = json.loads(line)\n",
    "        friends.append(profile['screen_name'])\n",
    "        \n",
    "for x in friends:\n",
    "    print(x)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory created for ohmostwanted\n",
      "Directory created for kiranjassal11\n",
      "Directory created for SkincareViralMY\n",
      "Directory created for VancityReynolds\n",
      "Directory created for MarkRuffalo\n",
      "Directory created for chrishemsworth\n",
      "Directory created for Renner4Real\n",
      "Directory created for prattprattpratt\n",
      "Directory created for RobertDowneyJr\n",
      "Directory created for ChrisEvans\n",
      "Directory created for twt_kecantikann\n",
      "Directory created for AshaLiyana21\n",
      "Directory created for AmandaImani91\n",
      "Directory created for brandonleong_\n",
      "Directory created for sashasaidin\n",
      "Directory created for jiayitan1993\n",
      "Directory created for tantannewsMY\n",
      "Directory created for zeriz4\n",
      "Directory created for imSarahLian\n",
      "Directory created for revlon\n",
      "Directory created for Colgate\n",
      "Directory created for PFCosmetics\n",
      "Directory created for OralB\n",
      "Directory created for missfazura\n",
      "Directory created for OlaySkin\n",
      "Directory created for Nor4Danish\n",
      "Directory created for Neutrogena\n",
      "Directory created for linoralow\n",
      "Directory created for HimalayaMAS\n",
      "Directory created for ClinelleMy\n",
      "Directory created for rimmellondonuk\n",
      "Directory created for bourjois_uk\n",
      "Directory created for bioreus\n",
      "Directory created for AishaLiyana\n",
      "Directory created for cetaphilMY\n",
      "Directory created for GarnierMalaysia\n",
      "Directory created for LOrealParisMY\n",
      "Directory created for CLEARMalaysia\n",
      "Directory created for SUNSILKMSIA\n",
      "Directory created for WatsonsPH\n",
      "Directory created for AaronDwiAziz\n",
      "Directory created for Neelofa\n",
      "Directory created for Shaheizy_Sam\n",
      "Directory created for CTNurhaliza11\n",
      "Directory created for yunamusic\n",
      "Directory created for zizanrajalawak\n",
      "Directory created for LisaSurihani\n",
      "Directory created for MaybellineMY\n",
      "Directory created for Zaidi_Aziz\n",
      "Directory created for BELLAZAHIR\n",
      "Directory created for ohbulancom\n",
      "Directory created for SimplySitiSB\n",
      "Directory created for kleioCo\n",
      "Directory created for WatsonsSG\n",
      "Directory created for amberchia\n"
     ]
    }
   ],
   "source": [
    "#creating separate directory for every  friends of watsons\n",
    "friends = []\n",
    "screen_name = 'watsonsmy'\n",
    "fname = \"output_watsons/{}/friends.json\".format(screen_name)\n",
    "\n",
    "with open(fname) as f:\n",
    "     for line in f:\n",
    "        profile = json.loads(line)\n",
    "        friends.append(profile['screen_name'])\n",
    "        \n",
    "#creating directory\n",
    "for friend in friends:\n",
    "    dirname = \"output_watsons/users/{}\".format(friend)\n",
    "    try:\n",
    "        os.makedirs(dirname, mode=0o755, exist_ok=True)\n",
    "        print(\"Directory created for\",friend)\n",
    "    except OSError:\n",
    "        print(\"Directory {} already exists\".format(dirname))\n",
    "    except Exception as e:\n",
    "        print(\"Error while creating directory {}\".format(dirname))\n",
    "        print(e)\n",
    "        sys.exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to run the command on that user, Skipping...  kiranjassal11\n",
      "Failed to run the command on that user, Skipping...  sashasaidin\n",
      "Failed to run the command on that user, Skipping...  jiayitan1993\n",
      "Failed to run the command on that user, Skipping...  tantannewsMY\n",
      "Failed to run the command on that user, Skipping...  zeriz4\n",
      "Failed to run the command on that user, Skipping...  imSarahLian\n",
      "Failed to run the command on that user, Skipping...  revlon\n",
      "Failed to run the command on that user, Skipping...  Colgate\n",
      "Failed to run the command on that user, Skipping...  PFCosmetics\n",
      "Failed to run the command on that user, Skipping...  OralB\n",
      "Failed to run the command on that user, Skipping...  missfazura\n",
      "Failed to run the command on that user, Skipping...  OlaySkin\n",
      "Failed to run the command on that user, Skipping...  Nor4Danish\n",
      "Failed to run the command on that user, Skipping...  Neutrogena\n",
      "Failed to run the command on that user, Skipping...  linoralow\n",
      "Failed to run the command on that user, Skipping...  HimalayaMAS\n",
      "Failed to run the command on that user, Skipping...  ClinelleMy\n",
      "Failed to run the command on that user, Skipping...  rimmellondonuk\n",
      "Failed to run the command on that user, Skipping...  bourjois_uk\n",
      "Failed to run the command on that user, Skipping...  bioreus\n",
      "Failed to run the command on that user, Skipping...  AishaLiyana\n",
      "Failed to run the command on that user, Skipping...  cetaphilMY\n",
      "Failed to run the command on that user, Skipping...  GarnierMalaysia\n",
      "Failed to run the command on that user, Skipping...  LOrealParisMY\n",
      "Failed to run the command on that user, Skipping...  CLEARMalaysia\n",
      "Failed to run the command on that user, Skipping...  SUNSILKMSIA\n",
      "Failed to run the command on that user, Skipping...  WatsonsPH\n",
      "Failed to run the command on that user, Skipping...  AaronDwiAziz\n",
      "Failed to run the command on that user, Skipping...  Neelofa\n",
      "Failed to run the command on that user, Skipping...  Shaheizy_Sam\n",
      "Failed to run the command on that user, Skipping...  CTNurhaliza11\n",
      "Failed to run the command on that user, Skipping...  yunamusic\n",
      "Failed to run the command on that user, Skipping...  zizanrajalawak\n",
      "Failed to run the command on that user, Skipping...  LisaSurihani\n",
      "Failed to run the command on that user, Skipping...  MaybellineMY\n",
      "Failed to run the command on that user, Skipping...  Zaidi_Aziz\n",
      "Failed to run the command on that user, Skipping...  BELLAZAHIR\n",
      "Failed to run the command on that user, Skipping...  ohbulancom\n",
      "Failed to run the command on that user, Skipping...  SimplySitiSB\n",
      "Failed to run the command on that user, Skipping...  kleioCo\n",
      "Failed to run the command on that user, Skipping...  WatsonsSG\n",
      "Failed to run the command on that user, Skipping...  amberchia\n",
      "task completed\n"
     ]
    }
   ],
   "source": [
    "#collecting friends information for every friends of watsons\n",
    "def paginate(items, n):\n",
    "    for i in range(0, len(items), n):\n",
    "        yield items[i:i+n]\n",
    "        \n",
    "MAX_FRIENDS = 15000\n",
    "max_pages = math.ceil(MAX_FRIENDS / 5000)\n",
    "\n",
    "friends = []\n",
    "screen_name = 'watsonsmy'\n",
    "fname = \"output_watsons/{}/friends.json\".format(screen_name)\n",
    "\n",
    "with open(fname) as f:\n",
    "     for line in f:\n",
    "        profile = json.loads(line)\n",
    "        friends.append(profile['screen_name'])\n",
    "        \n",
    "for friend in friends:\n",
    "    fname1 = \"output_watsons/users/{}/friends.json\".format(friend)\n",
    "    with open(fname1, 'w') as f1:\n",
    "        try:\n",
    "            for friends in Cursor(api.friends_ids, screen_name=friend).pages(max_pages):\n",
    "                for chunk in paginate(friends, 100):\n",
    "                    users = api.lookup_users(user_ids=chunk)\n",
    "                    for user in users:                   \n",
    "                        f1.write(json.dumps(user._json)+\"\\n\")\n",
    "                if len(friends) == 5000:\n",
    "                    print(\"More results available. Sleeping for 60 seconds to avoid rate limit\")\n",
    "                    time.sleep(60)\n",
    "        except tweepy.TweepError:\n",
    "            print(\"Failed to run the command on that user, Skipping...\" + '  '  +friend)\n",
    "\n",
    "print(\"task completed\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to run the command on that user, Skipping...  kiranjassal11\n",
      "More results available. Sleeping for 60 seconds to avoid rate limit\n",
      "More results available. Sleeping for 60 seconds to avoid rate limit\n",
      "More results available. Sleeping for 60 seconds to avoid rate limit\n",
      "More results available. Sleeping for 60 seconds to avoid rate limit\n",
      "More results available. Sleeping for 60 seconds to avoid rate limit\n",
      "More results available. Sleeping for 60 seconds to avoid rate limit\n",
      "More results available. Sleeping for 60 seconds to avoid rate limit\n",
      "More results available. Sleeping for 60 seconds to avoid rate limit\n",
      "More results available. Sleeping for 60 seconds to avoid rate limit\n",
      "More results available. Sleeping for 60 seconds to avoid rate limit\n",
      "Failed to run the command on that user, Skipping...  Renner4Real\n",
      "More results available. Sleeping for 60 seconds to avoid rate limit\n",
      "More results available. Sleeping for 60 seconds to avoid rate limit\n",
      "More results available. Sleeping for 60 seconds to avoid rate limit\n",
      "More results available. Sleeping for 60 seconds to avoid rate limit\n",
      "More results available. Sleeping for 60 seconds to avoid rate limit\n",
      "More results available. Sleeping for 60 seconds to avoid rate limit\n",
      "More results available. Sleeping for 60 seconds to avoid rate limit\n",
      "More results available. Sleeping for 60 seconds to avoid rate limit\n",
      "More results available. Sleeping for 60 seconds to avoid rate limit\n",
      "More results available. Sleeping for 60 seconds to avoid rate limit\n",
      "Failed to run the command on that user, Skipping...  twt_kecantikann\n",
      "More results available. Sleeping for 60 seconds to avoid rate limit\n",
      "More results available. Sleeping for 60 seconds to avoid rate limit\n",
      "More results available. Sleeping for 60 seconds to avoid rate limit\n",
      "More results available. Sleeping for 60 seconds to avoid rate limit\n",
      "More results available. Sleeping for 60 seconds to avoid rate limit\n",
      "More results available. Sleeping for 60 seconds to avoid rate limit\n",
      "More results available. Sleeping for 60 seconds to avoid rate limit\n",
      "More results available. Sleeping for 60 seconds to avoid rate limit\n",
      "More results available. Sleeping for 60 seconds to avoid rate limit\n",
      "Failed to run the command on that user, Skipping...  Colgate\n",
      "More results available. Sleeping for 60 seconds to avoid rate limit\n",
      "More results available. Sleeping for 60 seconds to avoid rate limit\n",
      "More results available. Sleeping for 60 seconds to avoid rate limit\n",
      "More results available. Sleeping for 60 seconds to avoid rate limit\n",
      "More results available. Sleeping for 60 seconds to avoid rate limit\n",
      "More results available. Sleeping for 60 seconds to avoid rate limit\n",
      "More results available. Sleeping for 60 seconds to avoid rate limit\n",
      "More results available. Sleeping for 60 seconds to avoid rate limit\n",
      "More results available. Sleeping for 60 seconds to avoid rate limit\n",
      "More results available. Sleeping for 60 seconds to avoid rate limit\n",
      "More results available. Sleeping for 60 seconds to avoid rate limit\n",
      "More results available. Sleeping for 60 seconds to avoid rate limit\n",
      "More results available. Sleeping for 60 seconds to avoid rate limit\n",
      "More results available. Sleeping for 60 seconds to avoid rate limit\n",
      "More results available. Sleeping for 60 seconds to avoid rate limit\n",
      "More results available. Sleeping for 60 seconds to avoid rate limit\n",
      "More results available. Sleeping for 60 seconds to avoid rate limit\n",
      "More results available. Sleeping for 60 seconds to avoid rate limit\n",
      "More results available. Sleeping for 60 seconds to avoid rate limit\n",
      "More results available. Sleeping for 60 seconds to avoid rate limit\n",
      "More results available. Sleeping for 60 seconds to avoid rate limit\n",
      "More results available. Sleeping for 60 seconds to avoid rate limit\n",
      "More results available. Sleeping for 60 seconds to avoid rate limit\n",
      "More results available. Sleeping for 60 seconds to avoid rate limit\n",
      "More results available. Sleeping for 60 seconds to avoid rate limit\n",
      "More results available. Sleeping for 60 seconds to avoid rate limit\n",
      "More results available. Sleeping for 60 seconds to avoid rate limit\n",
      "More results available. Sleeping for 60 seconds to avoid rate limit\n",
      "More results available. Sleeping for 60 seconds to avoid rate limit\n",
      "More results available. Sleeping for 60 seconds to avoid rate limit\n",
      "More results available. Sleeping for 60 seconds to avoid rate limit\n",
      "More results available. Sleeping for 60 seconds to avoid rate limit\n",
      "More results available. Sleeping for 60 seconds to avoid rate limit\n",
      "More results available. Sleeping for 60 seconds to avoid rate limit\n",
      "More results available. Sleeping for 60 seconds to avoid rate limit\n",
      "More results available. Sleeping for 60 seconds to avoid rate limit\n",
      "More results available. Sleeping for 60 seconds to avoid rate limit\n",
      "More results available. Sleeping for 60 seconds to avoid rate limit\n",
      "More results available. Sleeping for 60 seconds to avoid rate limit\n",
      "More results available. Sleeping for 60 seconds to avoid rate limit\n",
      "More results available. Sleeping for 60 seconds to avoid rate limit\n",
      "More results available. Sleeping for 60 seconds to avoid rate limit\n",
      "More results available. Sleeping for 60 seconds to avoid rate limit\n",
      "More results available. Sleeping for 60 seconds to avoid rate limit\n",
      "More results available. Sleeping for 60 seconds to avoid rate limit\n",
      "More results available. Sleeping for 60 seconds to avoid rate limit\n",
      "More results available. Sleeping for 60 seconds to avoid rate limit\n",
      "More results available. Sleeping for 60 seconds to avoid rate limit\n",
      "More results available. Sleeping for 60 seconds to avoid rate limit\n",
      "More results available. Sleeping for 60 seconds to avoid rate limit\n",
      "More results available. Sleeping for 60 seconds to avoid rate limit\n",
      "More results available. Sleeping for 60 seconds to avoid rate limit\n",
      "More results available. Sleeping for 60 seconds to avoid rate limit\n",
      "More results available. Sleeping for 60 seconds to avoid rate limit\n",
      "More results available. Sleeping for 60 seconds to avoid rate limit\n",
      "More results available. Sleeping for 60 seconds to avoid rate limit\n",
      "More results available. Sleeping for 60 seconds to avoid rate limit\n",
      "More results available. Sleeping for 60 seconds to avoid rate limit\n",
      "More results available. Sleeping for 60 seconds to avoid rate limit\n",
      "More results available. Sleeping for 60 seconds to avoid rate limit\n",
      "More results available. Sleeping for 60 seconds to avoid rate limit\n",
      "More results available. Sleeping for 60 seconds to avoid rate limit\n",
      "More results available. Sleeping for 60 seconds to avoid rate limit\n",
      "More results available. Sleeping for 60 seconds to avoid rate limit\n",
      "More results available. Sleeping for 60 seconds to avoid rate limit\n",
      "task completed\n"
     ]
    }
   ],
   "source": [
    "#collecting followers informaton for every friends of watsons\n",
    "def paginate(items,n):\n",
    "    for i in range(0, len(items), n):\n",
    "        yield items[i:i+n]\n",
    "        \n",
    "friends = []\n",
    "screen_name = 'watsonsmy'\n",
    "fname = \"output_watsons/{}/friends.json\".format(screen_name)\n",
    "\n",
    "with open(fname) as f:\n",
    "     for line in f:\n",
    "        profile = json.loads(line)\n",
    "        friends.append(profile['screen_name'])\n",
    "        \n",
    "        \n",
    "MAX_FRIENDS = 15000\n",
    "max_pages = math.ceil(MAX_FRIENDS / 5000)\n",
    "\n",
    "for friend in friends:\n",
    "    fname2 = \"output_watsons/users/{}/followers.json\".format(friend)\n",
    "    with open(fname2, 'w') as f2:\n",
    "        try:\n",
    "            for followers in Cursor(api.followers_ids, screen_name=friend).pages(max_pages):\n",
    "                for chunk in paginate(followers, 100):\n",
    "                    users = api.lookup_users(user_ids=chunk)\n",
    "                    for user in users:                    \n",
    "                        f2.write(json.dumps(user._json)+\"\\n\")    \n",
    "                if len(followers) == 5000:\n",
    "                    print(\"More results available. Sleeping for 60 seconds to avoid rate limit\")\n",
    "                    time.sleep(60)\n",
    "        except tweepy.TweepError:\n",
    "            print(\"Failed to run the command on that user, Skipping...\" + '  '  +friend)\n",
    "\n",
    "            \n",
    "print(\"task completed\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ohmostwanted', 'kiranjassal11', 'SkincareViralMY', 'VancityReynolds', 'MarkRuffalo', 'chrishemsworth', 'Renner4Real', 'prattprattpratt', 'RobertDowneyJr', 'ChrisEvans', 'twt_kecantikann', 'AshaLiyana21', 'AmandaImani91', 'brandonleong_', 'sashasaidin', 'jiayitan1993', 'tantannewsMY', 'zeriz4', 'imSarahLian', 'revlon', 'Colgate', 'PFCosmetics', 'OralB', 'missfazura', 'OlaySkin', 'Nor4Danish', 'Neutrogena', 'linoralow', 'HimalayaMAS', 'ClinelleMy', 'rimmellondonuk', 'bourjois_uk', 'bioreus', 'AishaLiyana', 'cetaphilMY', 'GarnierMalaysia', 'LOrealParisMY', 'CLEARMalaysia', 'SUNSILKMSIA', 'WatsonsPH', 'AaronDwiAziz', 'Neelofa', 'Shaheizy_Sam', 'CTNurhaliza11', 'yunamusic', 'zizanrajalawak', 'LisaSurihani', 'MaybellineMY', 'Zaidi_Aziz', 'BELLAZAHIR', 'ohbulancom', 'SimplySitiSB', 'kleioCo', 'WatsonsSG', 'amberchia']\n"
     ]
    }
   ],
   "source": [
    "#creating node and edge list\n",
    "import pandas as pd\n",
    "\n",
    "#creating node list\n",
    "node_list = []\n",
    "friends = []\n",
    "titles = ['name','screen_name','id','created_at','location','description','status_count','friends_count','followers_count']\n",
    "node_list.append(titles)\n",
    "screen_name = 'watsonsmy'\n",
    "\n",
    "\n",
    "#adding watsons in nodelist\n",
    "fname1 = \"output_watsons/{}/user_profile.json\".format(screen_name)\n",
    "\n",
    "details = []\n",
    "with open(fname1) as f:\n",
    "    profile = json.load(f)\n",
    "    details.append(profile['name'])\n",
    "    details.append(profile['screen_name'])\n",
    "    details.append(profile['id'])\n",
    "    details.append(profile['created_at'])\n",
    "    details.append(profile['location'])\n",
    "    details.append(profile['description'])\n",
    "    details.append(profile['statuses_count'])\n",
    "    details.append(profile['friends_count'])\n",
    "    details.append(profile['followers_count'])\n",
    "    node_list.append(details)\n",
    "    \n",
    "\n",
    "\n",
    "fname = \"output_watsons/{}/friends.json\".format(screen_name)\n",
    "#adding whatsons friend in nodelist\n",
    "with open(fname) as f:\n",
    "     for line in f:\n",
    "        profile = json.loads(line)\n",
    "        details = []\n",
    "        details.append(profile['name'])\n",
    "        details.append(profile['screen_name'])\n",
    "        details.append(profile['id'])\n",
    "        details.append(profile['created_at'])\n",
    "        details.append(profile['location'])\n",
    "        details.append(profile['description'])\n",
    "        details.append(profile['statuses_count'])\n",
    "        details.append(profile['friends_count'])\n",
    "        details.append(profile['followers_count'])\n",
    "        node_list.append(details)\n",
    "        friends.append(profile['screen_name'])\n",
    "\n",
    "print(friends)\n",
    "        \n",
    "#adding friends of watsons friends in nodelist\n",
    "for frnd in friends:\n",
    "    name_friends = \"output_watsons/users/{}/friends.json\".format(frnd)\n",
    "    with open(name_friends) as f:\n",
    "        for line in f:\n",
    "            details = []\n",
    "            friend = json.loads(line)\n",
    "            if friend not in node_list:\n",
    "                details.append(friend['name'])\n",
    "                details.append(friend['screen_name'])\n",
    "                details.append(friend['id'])\n",
    "                details.append(friend['created_at'])\n",
    "                details.append(friend['location'])\n",
    "                details.append(friend['description'])\n",
    "                details.append(friend['statuses_count'])\n",
    "                details.append(friend['friends_count'])\n",
    "                details.append(friend['followers_count'])\n",
    "                node_list.append(details)\n",
    "\n",
    "#creating edge list\n",
    "friend = []\n",
    "screen_name = 'watsonsmy'\n",
    "fname = \"output_watsons/{}/friends.json\".format(screen_name)\n",
    "\n",
    "with open(fname) as f:\n",
    "     for line in f:\n",
    "        profile = json.loads(line)\n",
    "        friend.append(profile['screen_name'])\n",
    "        \n",
    "        \n",
    "edge_list = []\n",
    "title = ['Source','Target']\n",
    "edge_list.append(title) \n",
    "\n",
    "for frnd in friend:\n",
    "    temp =[] \n",
    "    temp.append(screen_name)\n",
    "    temp.append(frnd)\n",
    "    edge_list.append(temp)\n",
    "\n",
    "for frnd in friend:\n",
    "    friends = []\n",
    "    \n",
    "    \"\"\"\n",
    "    followers  =[]\n",
    "    name_follower = \"output_watsons/users/{}/followers.json\".format(frnd)\n",
    "    with open(name_follower) as f:\n",
    "        for line in f:\n",
    "            follower = json.loads(line)\n",
    "            followers.append(follower['screen_name'])\n",
    "    \"\"\"\n",
    "            \n",
    "    name_friend = \"output_watsons/users/{}/friends.json\".format(frnd)\n",
    "    with open(name_friend) as f:\n",
    "        for line in f:\n",
    "            friend = json.loads(line)\n",
    "            friends.append(friend['screen_name'])\n",
    "    \n",
    "    \"\"\"\n",
    "    result = list(set(followers + friends))\n",
    "    for x in result:\n",
    "        temp = []\n",
    "        temp.append(frnd)\n",
    "        temp.append(x)\n",
    "        edge_list.append(temp)\n",
    "     \"\"\"\n",
    "    for x in friends:\n",
    "        temp = []\n",
    "        temp.append(frnd)\n",
    "        temp.append(x)\n",
    "        edge_list.append(temp)\n",
    "\n",
    "#Storing node and edge list in csv \n",
    "df1 = pd.DataFrame(node_list)   \n",
    "\n",
    "path1 = \"output_watsons/node_list.csv\"\n",
    "df1.to_csv(path1, header=False, index=False, index_label=None)\n",
    "\n",
    "df2 = pd.DataFrame(edge_list)\n",
    "\n",
    "path2 = \"output_watsons/edge_list.csv\"\n",
    "df2.to_csv(path2, header=False, index=False, index_label=None)\n",
    "\n",
    " \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
